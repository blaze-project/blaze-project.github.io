import{_ as e,c as s,b as n,o as r}from"./app-3-3moZD_.js";const l={};function t(i,a){return r(),s("div",null,a[0]||(a[0]=[n(`<h1 id="getting-started-with-auron-for-apache-spark" tabindex="-1"><a class="header-anchor" href="#getting-started-with-auron-for-apache-spark"><span>Getting Started with Auron for Apache Spark</span></a></h1><h2 id="build-from-source" tabindex="-1"><a class="header-anchor" href="#build-from-source"><span>Build from source</span></a></h2><p>To build Auron, please follow the steps below:</p><ol><li>Install Rust</li></ol><p>The native execution lib is written in Rust. So you&#39;re required to install Rust (nightly) first for compilation. We recommend you to use <a href="https://rustup.rs/" target="_blank" rel="noopener noreferrer">rustup</a>.</p><ol start="2"><li>Install JDK</li></ol><p>Auron has been well tested on jdk8/11/17, should work fine with higher versions.</p><ol start="3"><li>Check out the source code.</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token function">git</span> clone git@github.com:kwai/auron.git</span>
<span class="line"><span class="token builtin class-name">cd</span> auron</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div></div></div><ol start="4"><li>Build the project.</li></ol><p>Specify shims package of which spark version that you would like to run on.</p><p>Currently we have supported these shims:</p><ul><li>spark-3.0 - for spark3.0.x</li><li>spark-3.1 - for spark3.1.x</li><li>spark-3.2 - for spark3.2.x</li><li>spark-3.3 - for spark3.3.x</li><li>spark-3.4 - for spark3.4.x</li><li>spark-3.5 - for spark3.5.x.</li></ul><p>You could either build Auron in pre mode for debugging or in release mode to unlock the full potential of Auron.</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token assign-left variable">SHIM</span><span class="token operator">=</span>spark-3.5 <span class="token comment"># or spark-3.0/spark-3.1/spark-3.2/spark-3.3/spark-3.4/spark-3.5</span></span>
<span class="line"><span class="token assign-left variable">MODE</span><span class="token operator">=</span>release <span class="token comment"># or pre</span></span>
<span class="line"><span class="token assign-left variable">JDK</span><span class="token operator">=</span>jdk-8</span>
<span class="line">./build/mvn package -P<span class="token string">&quot;<span class="token variable">\${SHIM}</span>&quot;</span> -P<span class="token string">&quot;<span class="token variable">\${MODE}</span>&quot;</span> -P<span class="token variable">\${JDK}</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>After the build is finished, a fat Jar package that contains all the dependencies will be generated in the <code>target</code> directory.</p><h2 id="build-with-docker" tabindex="-1"><a class="header-anchor" href="#build-with-docker"><span>Build with docker</span></a></h2><p>You can use the following command to build a centos-7 compatible release:</p><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line"><span class="token assign-left variable">SHIM</span><span class="token operator">=</span>spark-3.5 <span class="token assign-left variable">MODE</span><span class="token operator">=</span>release ./release-docker.sh</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="run-spark-job-with-auron-accelerator" tabindex="-1"><a class="header-anchor" href="#run-spark-job-with-auron-accelerator"><span>Run Spark Job with Auron Accelerator</span></a></h2><p>This section describes how to submit and configure a Spark Job with Auron support.</p><ol><li><p>move auron jar package to spark client classpath (normally <code>spark-xx.xx.xx/jars/</code>).</p></li><li><p>add the follow confs to spark configuration in <code>spark-xx.xx.xx/conf/spark-default.conf</code>:</p></li></ol><div class="language-properties line-numbers-mode" data-highlighter="prismjs" data-ext="properties" data-title="properties"><pre><code><span class="line"><span class="token key attr-name">spark.auron.enable</span> <span class="token value attr-value">true</span></span>
<span class="line"><span class="token key attr-name">spark.sql.extensions</span> <span class="token value attr-value">org.apache.spark.sql.auron.AuronSparkSessionExtension</span></span>
<span class="line"><span class="token key attr-name">spark.shuffle.manager</span> <span class="token value attr-value">org.apache.spark.sql.execution.auron.shuffle.AuronShuffleManager</span></span>
<span class="line"><span class="token key attr-name">spark.memory.offHeap.enabled</span> <span class="token value attr-value">false</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># suggested executor memory configuration</span></span>
<span class="line"><span class="token key attr-name">spark.executor.memory</span> <span class="token value attr-value">4g</span></span>
<span class="line"><span class="token key attr-name">spark.executor.memoryOverhead</span> <span class="token value attr-value">4096</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li>submit a query with spark-sql, or other tools like spark-thriftserver:</li></ol><div class="language-bash line-numbers-mode" data-highlighter="prismjs" data-ext="sh" data-title="sh"><pre><code><span class="line">spark-sql <span class="token parameter variable">-f</span> tpcds/q01.sql</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div>`,25)]))}const p=e(l,[["render",t]]),c=JSON.parse('{"path":"/documents/getting-started.html","title":"Getting-Started","lang":"en-US","frontmatter":{"title":"Getting-Started"},"headers":[{"level":2,"title":"Build from source","slug":"build-from-source","link":"#build-from-source","children":[]},{"level":2,"title":"Build with docker","slug":"build-with-docker","link":"#build-with-docker","children":[]},{"level":2,"title":"Run Spark Job with Auron Accelerator","slug":"run-spark-job-with-auron-accelerator","link":"#run-spark-job-with-auron-accelerator","children":[]}],"git":{},"filePathRelative":"documents/getting-started.md"}');export{p as comp,c as data};
